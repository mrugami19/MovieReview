{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "\n",
    "def load_list(filename):\n",
    "    vocabulary = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for l in f:\n",
    "            vocabulary.append(l.strip())\n",
    "    return np.asarray(vocabulary)\n",
    "\n",
    "pos_related = load_list('./sentence_data/pos_related.txt')\n",
    "neg_related = load_list('./sentence_data/neg_related.txt')\n",
    "pos_unrelated = load_list('./sentence_data/pos_unrelated.txt')\n",
    "neg_unrelated = load_list('./sentence_data/neg_unrelated.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(466,)\n",
      "(83,)\n",
      "(388,)\n",
      "(34,)\n"
     ]
    }
   ],
   "source": [
    "print(pos_related.shape)\n",
    "print(neg_related.shape)\n",
    "print(pos_unrelated.shape)\n",
    "print(neg_unrelated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'not perfect by a long shot, but definitely good for a smile on a bad day.'\n",
      " 'the whole cast was great, each character had their own personality and charm.'\n",
      " 'even though it has one of the standard \"revenge price plot,\" this film is my favorite of vincent price\\'s work.'\n",
      " 'i really enjoyed this movie, it is really fun to watch get elvira into all these adventure, she is just great.'\n",
      " 'with more laugh than any other third-in-a-disney-series movie, hakuna matata is worth watching - if only for the hot tub scene which is still funny despite being a little bit predictable.'\n",
      " 'it is really a wonderful thriller i enjoyed very much'\n",
      " 'when my sister said this movie was gonna be good i had second thought but i watched it and it was actually funny'\n",
      " 'it touched me in a way that, even all these year later, still affects me.'\n",
      " 'i strongly recommend seeing for all'\n",
      " 'without a doubt, the best late night television ever.']\n"
     ]
    }
   ],
   "source": [
    "print(pos_related[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i had numerous problem with this film'\n",
      " 'dear god i do not know where to start why this movie sucked too much'\n",
      " 'i was pretty disappointed'\n",
      " 'if you are tempted to watch this movie, rip your eyeball out and flush them down the toilet'\n",
      " 'the music there was was annoying, and boring'\n",
      " 'someone must have been seriously joking when they made this film'\n",
      " 'ugly then, uglier now' 'this film is predictable'\n",
      " 'even the supporting male character are all \"bad\"'\n",
      " 'trust me, this is one let down movie that you want to avoid and this comes from one huge denzel washington fan']\n"
     ]
    }
   ],
   "source": [
    "print(neg_related[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549,)\n",
      "(549,)\n"
     ]
    }
   ],
   "source": [
    "related_set = np.hstack((pos_related, neg_related))\n",
    "print(related_set.shape)\n",
    "y_related = np.ones(related_set.shape)\n",
    "print(y_related.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(422,)\n",
      "(422,)\n"
     ]
    }
   ],
   "source": [
    "unrelated_set = np.hstack((pos_unrelated, neg_unrelated))\n",
    "print(unrelated_set.shape)\n",
    "y_unrelated = np.zeros(unrelated_set.shape)\n",
    "print(y_unrelated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(971,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.hstack((related_set, unrelated_set))\n",
    "y = np.hstack((y_related, y_unrelated))\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "tf_vectorizer = CountVectorizer(lowercase=True, max_df=1.0, min_df=1, binary=False, token_pattern=token)\n",
    "tf_vectorizer.set_params(ngram_range=(1,1))\n",
    "\n",
    "X_vectorized = tf_vectorizer.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(650,)\n",
      "(321,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :  0.99538\n",
      "Test :  0.75701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Train : ', np.around(clf.score(X_train, y_train),5))\n",
    "print('Test : ', np.around(clf.score(X_test, y_test),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "y_predict = clf.predict(X_test)\n",
    "print(np.sum(y_predict == y_test))\n",
    "print(np.sum(y_predict != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not perfect by a long shot, but definitely good for a smile on a bad day.\n",
      "the whole cast was great, each character had their own personality and charm.\n",
      "even though it has one of the standard \"revenge price plot,\" this film is my favorite of vincent price's work.\n",
      "i really enjoyed this movie, it is really fun to watch get elvira into all these adventure, she is just great.\n",
      "with more laugh than any other third-in-a-disney-series movie, hakuna matata is worth watching - if only for the hot tub scene which is still funny despite being a little bit predictable.\n",
      "it is really a wonderful thriller i enjoyed very much\n",
      "when my sister said this movie was gonna be good i had second thought but i watched it and it was actually funny\n",
      "it touched me in a way that, even all these year later, still affects me.\n",
      "i strongly recommend seeing for all\n",
      "without a doubt, the best late night television ever.\n"
     ]
    }
   ],
   "source": [
    "for sentence in X[:10] :\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(path, X):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(X, f)\n",
    "def open_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X\n",
    "\n",
    "X_te_clean = open_pickle(\"./pickles/imdb_x_te_clean.pickle\")\n",
    "y_te = open_pickle(\"./pickles/imdb_y_te.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sentence(corpus):\n",
    "    from textblob import TextBlob\n",
    "    text = TextBlob(corpus)\n",
    "    i = 0\n",
    "#     for sentence in text.sentences:\n",
    "#         print(i, ':', sentence)\n",
    "#         i += 1\n",
    "    return text.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-bb407fda5336>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprint_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_te_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-f07093b4f895>\u001b[0m in \u001b[0;36mprint_sentence\u001b[1;34m(corpus)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprint_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "sample = print_sentence(X_te_clean[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
