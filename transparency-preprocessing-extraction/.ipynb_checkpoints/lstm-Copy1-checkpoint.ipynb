{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1937,
     "status": "ok",
     "timestamp": 1521769348463,
     "user": {
      "displayName": "Anneke Hidayat",
      "photoUrl": "//lh5.googleusercontent.com/-tCwEjKDu5AE/AAAAAAAAAAI/AAAAAAAAACQ/oPkh_bQuHFk/s50-c-k-no/photo.jpg",
      "userId": "112205419822885524165"
     },
     "user_tz": 300
    },
    "id": "Ukaft_hQgfrB",
    "outputId": "b4f7fa22-9d40-4c79-ca79-74fd9e7204af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential  \n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1986,
     "status": "ok",
     "timestamp": 1521769350466,
     "user": {
      "displayName": "Anneke Hidayat",
      "photoUrl": "//lh5.googleusercontent.com/-tCwEjKDu5AE/AAAAAAAAAAI/AAAAAAAAACQ/oPkh_bQuHFk/s50-c-k-no/photo.jpg",
      "userId": "112205419822885524165"
     },
     "user_tz": 300
    },
    "id": "AuXqhJYDg08Y",
    "outputId": "c3d9cf1f-ecd6-433d-cb2a-6b75bb9368d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1050,
     "output_extras": [
      {
       "item_id": 4
      },
      {
       "item_id": 5
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29282,
     "status": "error",
     "timestamp": 1521769061827,
     "user": {
      "displayName": "Anneke Hidayat",
      "photoUrl": "//lh5.googleusercontent.com/-tCwEjKDu5AE/AAAAAAAAAAI/AAAAAAAAACQ/oPkh_bQuHFk/s50-c-k-no/photo.jpg",
      "userId": "112205419822885524165"
     },
     "user_tz": 300
    },
    "id": "u6X_uyoST1sm",
    "outputId": "f6ffc1bc-9ca6-4491-e1d4-c23f83a0134c"
   },
   "outputs": [],
   "source": [
    "# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "# !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "# !apt-get update -qq 2>&1 > /dev/null\n",
    "# !apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "# from google.colab import auth\n",
    "# auth.authenticate_user()\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "# creds = GoogleCredentials.get_application_default()\n",
    "# import getpass\n",
    "# !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "# vcode = getpass.getpass()\n",
    "# !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 52,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2475,
     "status": "ok",
     "timestamp": 1521768533713,
     "user": {
      "displayName": "Anneke Hidayat",
      "photoUrl": "//lh5.googleusercontent.com/-tCwEjKDu5AE/AAAAAAAAAAI/AAAAAAAAACQ/oPkh_bQuHFk/s50-c-k-no/photo.jpg",
      "userId": "112205419822885524165"
     },
     "user_tz": 300
    },
    "id": "dwVMVXSBaJgd",
    "outputId": "c419769d-175b-4710-cf01-c238f901408f"
   },
   "outputs": [],
   "source": [
    "# !mkdir -p drive\n",
    "# !google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eJnWaUwlVwDk"
   },
   "outputs": [],
   "source": [
    "# !ls drive/Project/Transparency\\ Text\\ Classification\n",
    "\n",
    "# import os\n",
    "# os.chdir('./drive/Colab Notebooks/text-classification-transparency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 813,
     "status": "ok",
     "timestamp": 1521769354410,
     "user": {
      "displayName": "Anneke Hidayat",
      "photoUrl": "//lh5.googleusercontent.com/-tCwEjKDu5AE/AAAAAAAAAAI/AAAAAAAAACQ/oPkh_bQuHFk/s50-c-k-no/photo.jpg",
      "userId": "112205419822885524165"
     },
     "user_tz": 300
    },
    "id": "uzQ9TZfId0Ta",
    "outputId": "582bb078-ca63-4c07-83f6-fa9ef9f212f0"
   },
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "47ryc8z7gfrH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 242,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 6
      }
     ],
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25784,
     "status": "ok",
     "timestamp": 1521446036237,
     "user": {
      "displayName": "Anneke Hidayat",
      "photoUrl": "//lh5.googleusercontent.com/-tCwEjKDu5AE/AAAAAAAAAAI/AAAAAAAAACQ/oPkh_bQuHFk/s50-c-k-no/photo.jpg",
      "userId": "112205419822885524165"
     },
     "user_tz": 300
    },
    "id": "kFqsPKKxh4Nq",
    "outputId": "0205772a-8462-47b8-ee9d-00b8e6b7532f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# for fn in uploaded.keys():\n",
    "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "#       name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UNNaNqXCgfrK"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "def load_list(filename):\n",
    "    vocabulary = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for l in f:\n",
    "            vocabulary.append(l.strip())\n",
    "    return np.asarray(vocabulary)\n",
    "\n",
    "def load_csv(filename):\n",
    "    import csv\n",
    "    \n",
    "    sentence = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            sentence.append(str(row))\n",
    "    return np.asarray(sentence).flatten()\n",
    "\n",
    "def generate_token_sequence(X_corpus, word_dict, token):\n",
    "    import re\n",
    "\n",
    "    token_pattern = re.compile(token)\n",
    "    X = []\n",
    "    i=0\n",
    "    for sentence in X_corpus:\n",
    "        split = token_pattern.findall(sentence)\n",
    "        seq = []\n",
    "        for word in split:\n",
    "            try:\n",
    "                seq.append(word_dict[word])\n",
    "            except KeyError:\n",
    "                continue\n",
    "        X.append(seq)\n",
    "\n",
    "    return np.asarray(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6279,
     "status": "ok",
     "timestamp": 1521769368125,
     "user": {
      "displayName": "Anneke Hidayat",
      "photoUrl": "//lh5.googleusercontent.com/-tCwEjKDu5AE/AAAAAAAAAAI/AAAAAAAAACQ/oPkh_bQuHFk/s50-c-k-no/photo.jpg",
      "userId": "112205419822885524165"
     },
     "user_tz": 300
    },
    "id": "RtKFxM4vxWeO",
    "outputId": "b98ea7b7-0837-414d-b1e4-9ca0a9e66f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :  1333\n",
      "Test :  667\n",
      "Words : 4532\n",
      "Generate token sequence...\n",
      "Generate pad sequences...\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (1333, 100)\n",
      "x_test shape: (667, 100)\n",
      "Generate one hot\n",
      "X_train one hot done...\n",
      "X_test one hot done...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "  \n",
    "# print('load data...')\n",
    "# pos_related = load_csv('pos_related.csv')\n",
    "# neg_related = load_csv('neg_related.csv')\n",
    "# pos_unrelated = load_csv('pos_unrelated.csv')\n",
    "# neg_unrelated = load_csv('neg_unrelated.csv')\n",
    "  \n",
    "# print(pos_related.shape)\n",
    "# print(neg_related.shape)\n",
    "# print(pos_unrelated.shape)\n",
    "# print(neg_unrelated.shape)\n",
    "  \n",
    "# print('Stack the data...')\n",
    "\n",
    "# related_set = np.hstack((pos_related, neg_related))\n",
    "# y_related = np.ones(related_set.shape)\n",
    "\n",
    "# unrelated_set = np.hstack((pos_unrelated, neg_unrelated))\n",
    "# y_unrelated = np.zeros(unrelated_set.shape)\n",
    "  \n",
    "# print('[related, unrelated] : [%d, %d]' %(y_related.shape[0], y_unrelated.shape[0])) \n",
    "  \n",
    "# X_stack = np.hstack((related_set, unrelated_set))\n",
    "# y_stack = np.hstack((y_related, y_unrelated))\n",
    "\n",
    "# print('Total data :', len(X_stack))\n",
    "# print('Split train-test data...')\n",
    "# import numpy as np\n",
    "# import random\n",
    "\n",
    "# random.seed(42)\n",
    "# param = 2/3\n",
    "# partition = int(len(X_stack) * param)\n",
    "# indices = random.sample(range(len(X_stack)),partition)\n",
    "\n",
    "# X_train_corpus = np.asarray(X_stack[indices])\n",
    "# X_test_corpus = np.asarray(np.delete(X_stack,indices))\n",
    "# y_train = y_stack[indices]\n",
    "# y_test = np.delete(y_stack, indices)\n",
    "\n",
    "# Clean the special characters\n",
    "# for i in range(len(X_train_corpus)):\n",
    "#   X_train_corpus[i] = re.sub('[^A-Za-z0-9 ]+', '', X_train_corpus[i])\n",
    "# for i in range(len(X_test_corpus)):\n",
    "#   X_test_corpus[i] = re.sub('[^A-Za-z0-9 ]+', '', X_test_corpus[i])\n",
    "  \n",
    "import pickle\n",
    "def save_pickle(path, X):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(X, f)\n",
    "def open_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X\n",
    "\n",
    "X_train_sent = open_pickle(\"./sentence_data/imdb_sentence_xtrain.pickle\")\n",
    "X_test_sent = open_pickle(\"./sentence_data/imdb_sentence_xtest.pickle\")\n",
    "y_train = open_pickle(\"./sentence_data/imdb_sentence_ytrain.pickle\")\n",
    "y_test = open_pickle(\"./sentence_data/imdb_sentence_ytest.pickle\")\n",
    "\n",
    "print('Train : ',len(X_train_sent))\n",
    "print('Test : ', len(X_test_sent))\n",
    "  \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "tf_vectorizer = CountVectorizer(lowercase=True, max_df=1.0, min_df=1, binary=False, token_pattern=token)\n",
    "tf_vectorizer.set_params(ngram_range=(1,1))\n",
    "\n",
    "tf_vectorizer.fit(X_train_sent)\n",
    "\n",
    "word_dict = tf_vectorizer.vocabulary_\n",
    "dict_len = len(tf_vectorizer.get_feature_names())\n",
    "word_feature = tf_vectorizer.get_feature_names()\n",
    "  \n",
    "print('Words :', len(tf_vectorizer.get_feature_names()))\n",
    "  \n",
    "print('Generate token sequence...')\n",
    "X_train = generate_token_sequence(X_train_sent, word_dict, token)\n",
    "X_test = generate_token_sequence(X_test_sent, word_dict, token)\n",
    "\n",
    "del X_train_sent\n",
    "del X_test_sent\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print('Generate pad sequences...')\n",
    "print('Pad sequences (samples x time)')\n",
    "\n",
    "maxlen=100\n",
    "x_train = pad_sequences(X_train, maxlen=maxlen, padding='pre', truncating='pre', value=0)\n",
    "x_test = pad_sequences(X_test, maxlen=maxlen, padding='pre', truncating='pre', value=0)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "del X_train\n",
    "del X_test\n",
    "\n",
    "print('Generate one hot')\n",
    "\n",
    "def generate_one_hot(X):\n",
    "    X_one_hot = []\n",
    "  \n",
    "    for sent in X:\n",
    "        sent_reverse = []\n",
    "        for idx in sent:\n",
    "            sent_reverse.append(word_feature[idx])\n",
    "        sent_transform = tf_vectorizer.transform(sent_reverse).todense()\n",
    "        X_one_hot.append(sent_transform)\n",
    "        del sent_transform\n",
    "    return np.array(X_one_hot)\n",
    "\n",
    "X_train_hot = generate_one_hot(x_train)\n",
    "print('X_train one hot done...')\n",
    "del x_train\n",
    "X_test_hot = generate_one_hot(x_test)\n",
    "print('X_test one hot done...')\n",
    "del x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AiPa8ojBgYZS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1333, 100, 4532)\n",
      "(667, 100, 4532)\n"
     ]
    }
   ],
   "source": [
    "# X_test_hot = generate_one_hot(x_test)\n",
    "print(X_train_hot.shape)\n",
    "print(X_test_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 762,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1521769404193,
     "user": {
      "displayName": "Anneke Hidayat",
      "photoUrl": "//lh5.googleusercontent.com/-tCwEjKDu5AE/AAAAAAAAAAI/AAAAAAAAACQ/oPkh_bQuHFk/s50-c-k-no/photo.jpg",
      "userId": "112205419822885524165"
     },
     "user_tz": 300
    },
    "id": "uWMw8Gvugej6",
    "outputId": "ce0e4cb5-aebc-4cbb-dec0-88c541818e78"
   },
   "outputs": [],
   "source": [
    "# !cat /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 235,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 307,
     "status": "error",
     "timestamp": 1521768726348,
     "user": {
      "displayName": "Anneke Hidayat",
      "photoUrl": "//lh5.googleusercontent.com/-tCwEjKDu5AE/AAAAAAAAAAI/AAAAAAAAACQ/oPkh_bQuHFk/s50-c-k-no/photo.jpg",
      "userId": "112205419822885524165"
     },
     "user_tz": 300
    },
    "id": "4aATnUVllkpU",
    "outputId": "9485115e-6954-4608-a439-fca6ac12ab33"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# print(len(X_train_corpus[4].split()))\n",
    "# print(X_train_corpus[4])\n",
    "\n",
    "# X_sent_len = np.zeros(X_stack.shape[0])\n",
    "\n",
    "# for i in range(len(X_sent_len)):\n",
    "#   X_sent_len[i] = len(X_stack[i].split())\n",
    "\n",
    "# X_train_sent_len = np.zeros(len(X_train_corpus))\n",
    "# X_test_sent_len = np.zeros(len(X_test_corpus))\n",
    "\n",
    "# for i in range(len(X_train_sent_len)):\n",
    "#   X_train_sent_len[i] = len(X_train_corpus[i].split())\n",
    "\n",
    "# for i in range(len(X_test_sent_len)):\n",
    "#   X_test_sent_len[i] = len(X_test_corpus[i].split())\n",
    "\n",
    "# def print_word_stat(title, X):\n",
    "#   print()\n",
    "#   print('--', title, 'Statistics --')\n",
    "\n",
    "#   print('Total sentences ', len(X))\n",
    "#   print('Max \\t: ', int(np.max(X)))\n",
    "#   print('Min \\t: ', int(np.min(X)))\n",
    "#   print('Mean \\t: ', int(np.mean(X)))\n",
    "#   print('Median \\t: ', int(np.median(X)))\n",
    "#   print()\n",
    "\n",
    "# print_word_stat('Whole corpus', X_sent_len)\n",
    "# print_word_stat('Train Corpus', X_train_sent_len)\n",
    "# print_word_stat('Test Corpus', X_test_sent_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MIsvPv42kclW"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_pickle(path, X):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(X, f)\n",
    "def open_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X\n",
    "  \n",
    "  \n",
    "# save_pickle(\"./imdb_sentence_xtrain.pickle\", X_train_corpus)\n",
    "# save_pickle(\"./imdb_sentence_xtest.pickle\", X_test_corpus)\n",
    "# save_pickle(\"./imdb_sentence_ytrain.pickle\", y_train)\n",
    "# save_pickle(\"./imdb_sentence_ytest.pickle\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 52,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1521588861106,
     "user": {
      "displayName": "Anneke Hidayat",
      "photoUrl": "//lh5.googleusercontent.com/-tCwEjKDu5AE/AAAAAAAAAAI/AAAAAAAAACQ/oPkh_bQuHFk/s50-c-k-no/photo.jpg",
      "userId": "112205419822885524165"
     },
     "user_tz": 300
    },
    "id": "zJkmuwTByoRs",
    "outputId": "0acb6821-6794-4c80-8495-26f9cd4328c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 50)\n",
      "(300, 50)\n"
     ]
    }
   ],
   "source": [
    "# Split validation and test set\n",
    "\n",
    "# x_val = np.asarray(x_test[:int(x_test.shape[0]/2)])\n",
    "# y_val = np.asarray(y_test[:int(len(y_test)/2)])\n",
    "# x_te = np.asarray(x_test[int(x_test.shape[0]/2):])\n",
    "# y_te = np.asarray(y_test[int(len(y_test)/2):])\n",
    "\n",
    "# print(x_val.shape)\n",
    "# print(x_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 332,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      },
      {
       "item_id": 3
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1521769437995,
     "user": {
      "displayName": "Anneke Hidayat",
      "photoUrl": "//lh5.googleusercontent.com/-tCwEjKDu5AE/AAAAAAAAAAI/AAAAAAAAACQ/oPkh_bQuHFk/s50-c-k-no/photo.jpg",
      "userId": "112205419822885524165"
     },
     "user_tz": 300
    },
    "id": "CO7kDdl3gfsJ",
    "outputId": "9bb7acc6-db2c-452a-daee-0f150a914c23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anneke\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\Anneke\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"relu\", recurrent_activation=\"tanh\", input_shape=(None, 453..., units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 10)                181720    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 181,731\n",
      "Trainable params: 181,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# checkpointer = ModelCheckpoint(filepath='./weights_embed_10.hdf5', verbose=1, save_best_only=False)\n",
    "import numpy as np\n",
    "import os\n",
    "import random as rn\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "rn.seed(12345)\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "\n",
    "K.set_session(sess) \n",
    "\n",
    "\n",
    "hidden_neurons = 10\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# model.add(Embedding(dict_len, 100))\n",
    "model.add(LSTM(output_dim=hidden_neurons, input_dim=dict_len, activation='relu', recurrent_activation='tanh'))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 401,
     "output_extras": [
      {
       "item_id": 273
      },
      {
       "item_id": 363
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 141492,
     "status": "ok",
     "timestamp": 1521769593145,
     "user": {
      "displayName": "Anneke Hidayat",
      "photoUrl": "//lh5.googleusercontent.com/-tCwEjKDu5AE/AAAAAAAAAAI/AAAAAAAAACQ/oPkh_bQuHFk/s50-c-k-no/photo.jpg",
      "userId": "112205419822885524165"
     },
     "user_tz": 300
    },
    "id": "8cVamRebgfsY",
    "outputId": "e8984fc4-dee6-4cc8-87e4-f61d6b0bef04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 1333 samples, validate on 667 samples\n",
      "Epoch 1/50\n",
      "1333/1333 [==============================] - 29s 22ms/step - loss: 0.6931 - acc: 0.4929 - val_loss: 0.6935 - val_acc: 0.4558\n",
      "Epoch 2/50\n",
      "1333/1333 [==============================] - 24s 18ms/step - loss: 0.6929 - acc: 0.5221 - val_loss: 0.6939 - val_acc: 0.4558\n",
      "Epoch 3/50\n",
      "1333/1333 [==============================] - 24s 18ms/step - loss: 0.6924 - acc: 0.5221 - val_loss: 0.6943 - val_acc: 0.4558\n",
      "Epoch 4/50\n",
      "1333/1333 [==============================] - 23s 18ms/step - loss: 0.8611 - acc: 0.4801 - val_loss: 2.2099 - val_acc: 0.4558\n",
      "Epoch 5/50\n",
      "1333/1333 [==============================] - 23s 18ms/step - loss: 0.7040 - acc: 0.5221 - val_loss: 0.6929 - val_acc: 0.4558\n",
      "Epoch 6/50\n",
      "1333/1333 [==============================] - 24s 18ms/step - loss: 0.6850 - acc: 0.5221 - val_loss: 0.6928 - val_acc: 0.4558\n",
      "Epoch 7/50\n",
      "1333/1333 [==============================] - 24s 18ms/step - loss: 0.6833 - acc: 0.5221 - val_loss: 0.6925 - val_acc: 0.4558\n",
      "Epoch 8/50\n",
      "1333/1333 [==============================] - 24s 18ms/step - loss: 0.6814 - acc: 0.5221 - val_loss: 0.6921 - val_acc: 0.4558\n",
      "Epoch 9/50\n",
      "1333/1333 [==============================] - 23s 18ms/step - loss: 0.6791 - acc: 0.5221 - val_loss: 0.6915 - val_acc: 0.4558\n",
      "Epoch 10/50\n",
      "1333/1333 [==============================] - 23s 17ms/step - loss: 0.6762 - acc: 0.5221 - val_loss: 0.6907 - val_acc: 0.4558\n",
      "Epoch 11/50\n",
      "1333/1333 [==============================] - 24s 18ms/step - loss: 0.6725 - acc: 0.5221 - val_loss: 0.6894 - val_acc: 0.4558\n",
      "Epoch 12/50\n",
      "1333/1333 [==============================] - 24s 18ms/step - loss: 0.6674 - acc: 0.5221 - val_loss: 0.6871 - val_acc: 0.4558\n",
      "Epoch 13/50\n",
      "1333/1333 [==============================] - 24s 18ms/step - loss: 0.6620 - acc: 0.5236 - val_loss: 0.6863 - val_acc: 0.4558\n",
      "Epoch 14/50\n",
      "1333/1333 [==============================] - 23s 17ms/step - loss: 0.6534 - acc: 0.5296 - val_loss: 0.6838 - val_acc: 0.4558\n",
      "Epoch 15/50\n",
      "1333/1333 [==============================] - 23s 18ms/step - loss: 0.6398 - acc: 0.5514 - val_loss: 0.6795 - val_acc: 0.4588\n",
      "Epoch 16/50\n",
      "1333/1333 [==============================] - 23s 18ms/step - loss: 0.6186 - acc: 0.6429 - val_loss: 0.6724 - val_acc: 0.4693\n",
      "Epoch 17/50\n",
      "1333/1333 [==============================] - 23s 17ms/step - loss: 0.5940 - acc: 0.7742 - val_loss: 0.6648 - val_acc: 0.5037\n",
      "Epoch 18/50\n",
      "1333/1333 [==============================] - 23s 17ms/step - loss: 0.5762 - acc: 0.8312 - val_loss: 0.6586 - val_acc: 0.5292\n",
      "Epoch 19/50\n",
      "1333/1333 [==============================] - 24s 18ms/step - loss: 0.5412 - acc: 0.8627 - val_loss: 0.6623 - val_acc: 0.5652\n",
      "Epoch 20/50\n",
      " 832/1333 [=================>............] - ETA: 6s - loss: 0.5139 - acc: 0.8762"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "# hist = model.fit(x_train, y_train, epochs=50, verbose=1, validation_data=(x_val,y_val), shuffle=False, callbacks=[checkpointer])\n",
    "hist = model.fit(X_train_hot, y_train, epochs=50, verbose=1, validation_data=(X_test_hot,y_test), shuffle=False)\n",
    "# hist = model.fit(X_train_hot, y_train, epochs=10, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10211,
     "status": "ok",
     "timestamp": 1521769683866,
     "user": {
      "displayName": "Anneke Hidayat",
      "photoUrl": "//lh5.googleusercontent.com/-tCwEjKDu5AE/AAAAAAAAAAI/AAAAAAAAACQ/oPkh_bQuHFk/s50-c-k-no/photo.jpg",
      "userId": "112205419822885524165"
     },
     "user_tz": 300
    },
    "id": "VSu2u9uGgfsd",
    "outputId": "034a49d6-3a84-4722-ca9e-c8af8701e38a"
   },
   "outputs": [],
   "source": [
    "# del X_test_hot\n",
    "\n",
    "y_pred_train = model.predict(X_train_hot)\n",
    "y_pred_test = model.predict(X_test_hot)\n",
    "\n",
    "y_pred_tr = []\n",
    "y_pred_te = []\n",
    "\n",
    "for pred in y_pred_train:\n",
    "    if pred > 0.5:\n",
    "        y_pred_tr.append(1)\n",
    "    else:\n",
    "        y_pred_tr.append(0)\n",
    "        \n",
    "for pred in y_pred_test:\n",
    "    if pred > 0.5:\n",
    "        y_pred_te.append(1)\n",
    "    else:\n",
    "        y_pred_te.append(0)\n",
    "\n",
    "        \n",
    "print('Train : ', np.around(np.sum(y_train == y_pred_tr)/len(y_pred_tr),3))\n",
    "print('Test : ',np.around(np.sum(y_test == y_pred_te)/len(y_pred_te),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1521590693539,
     "user": {
      "displayName": "Anneke Hidayat",
      "photoUrl": "//lh5.googleusercontent.com/-tCwEjKDu5AE/AAAAAAAAAAI/AAAAAAAAACQ/oPkh_bQuHFk/s50-c-k-no/photo.jpg",
      "userId": "112205419822885524165"
     },
     "user_tz": 300
    },
    "id": "yAsLbopggfsg",
    "outputId": "c93f035a-1a59-454e-c060-aef8f42be80e"
   },
   "outputs": [],
   "source": [
    "print(hist.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 52,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1521590694039,
     "user": {
      "displayName": "Anneke Hidayat",
      "photoUrl": "//lh5.googleusercontent.com/-tCwEjKDu5AE/AAAAAAAAAAI/AAAAAAAAACQ/oPkh_bQuHFk/s50-c-k-no/photo.jpg",
      "userId": "112205419822885524165"
     },
     "user_tz": 300
    },
    "id": "n-GcNFUH3mID",
    "outputId": "c55bf197-5c3a-427c-d711-3a0e5accaa19"
   },
   "outputs": [],
   "source": [
    "n_epoch = np.argmin(hist.history['val_loss'])\n",
    "print(n_epoch)\n",
    "print(np.around(hist.history['val_loss'][n_epoch], 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.around(hist.history['val_acc'][n_epoch], 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_stack = np.vstack((hist.history['loss'],hist.history['acc'],hist.history['val_loss'],hist.history['val_acc']))\n",
    "for i in range(hist_stack.shape[1]):\n",
    "    print(\"%f\\t%f\\t%f\\t%f\" %(hist_stack[0, i],hist_stack[1, i],hist_stack[2, i],hist_stack[3, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.plot(hist.history['loss'], 'm--')\n",
    "plt.plot(hist.history['val_loss'], 'y--')\n",
    "plt.title('model loss history')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['tr_acc', 'te_acc','tr_loss', 'te_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NYjoVJBdAuHp"
   },
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yZJCXqHC878Z"
   },
   "outputs": [],
   "source": [
    "# from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "# def train_and_evaluate_model(model, data[train], labels[train], data[test], labels[test)):\n",
    "#     model.fit...\n",
    "#     # fit and evaluate here.\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     n_folds = 10\n",
    "#     data, labels, header_info = load_data()\n",
    "#     skf = StratifiedKFold(labels, n_folds=n_folds, shuffle=True)\n",
    "\n",
    "#     for i, (train, test) in enumerate(skf):\n",
    "#             print \"Running Fold\", i+1, \"/\", n_folds\n",
    "#             model = None # Clearing the NN.\n",
    "#             model = create_model()\n",
    "#             train_and_evaluate_model(model, data[train], labels[train], data[test], labels[test])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "lstm.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
