{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "def load_imdb(path, shuffle=True, random_state=42):\n",
    "    import glob \n",
    "    print(\"Loading the imdb data\")\n",
    "    \n",
    "    train_neg_files = glob.glob(path+\"/train/neg/*.txt\")\n",
    "    train_pos_files = glob.glob(path+\"/train/pos/*.txt\")\n",
    "    \n",
    "    X_train_corpus = []\n",
    "    y_train = []\n",
    "    \n",
    "    for tnf in train_neg_files:\n",
    "        f = open(tnf, 'r', encoding=\"utf8\")\n",
    "        line = f.read()\n",
    "        #line = line[:len(line)/2]\n",
    "        X_train_corpus.append(line)\n",
    "        y_train.append(0)\n",
    "        f.close()\n",
    "    \n",
    "    for tpf in train_pos_files:\n",
    "        f = open(tpf, 'r', encoding=\"utf8\")\n",
    "        line = f.read()\n",
    "        #line = line[:len(line)/2]\n",
    "        X_train_corpus.append(line)\n",
    "        y_train.append(1)\n",
    "        f.close()\n",
    "    \n",
    "    print(\"Train Data loaded.\")\n",
    "    \n",
    "    test_neg_files = glob.glob(path+\"/test/neg/*.txt\")\n",
    "    test_pos_files = glob.glob(path+\"/test/pos/*.txt\")\n",
    "    \n",
    "    X_test_corpus = []\n",
    "    y_test = []\n",
    "    \n",
    "    for tnf in test_neg_files:\n",
    "        f = open(tnf, 'r', encoding=\"utf8\")\n",
    "        X_test_corpus.append(f.read())\n",
    "        y_test.append(0)\n",
    "        f.close()\n",
    "    \n",
    "    for tpf in test_pos_files:\n",
    "        f = open(tpf, 'r', encoding=\"utf8\")\n",
    "        X_test_corpus.append(f.read())\n",
    "        y_test.append(1)\n",
    "        f.close()\n",
    "    \n",
    "    print(\"Test Data loaded.\")\n",
    "    \n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.seed(random_state)\n",
    "        indices = np.random.permutation(len(y_train))       \n",
    "        \n",
    "        X_train_corpus = [X_train_corpus[i] for i in indices]\n",
    "        y_train = y_train[indices]\n",
    "        \n",
    "        indices = np.random.permutation(len(y_test))\n",
    "        \n",
    "        X_test_corpus = [X_test_corpus[i] for i in indices]\n",
    "        y_test = y_test[indices]\n",
    "       \n",
    "    \n",
    "    return X_train_corpus, y_train, X_test_corpus , y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read and load the contraction list (or any text files)\n",
    "'''\n",
    "def load_list(filename, split_delimiter):\n",
    "    vocabulary = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for l in f:\n",
    "            vocabulary.append(l.strip().split(split_delimiter))\n",
    "    return np.asarray(vocabulary)\n",
    "\n",
    "'''\n",
    "Clean the HTML tags from the corpus\n",
    "'''\n",
    "def cleanhtml(text):\n",
    "#     cleanr = re.compile('<.*?>')\n",
    "#     cleantag = re.sub(cleanr, '', text)\n",
    "    cleantag = re.sub(re.compile('<.*?>'), '', text)\n",
    "    cleantext = cleantag.replace('br', '')\n",
    "    return cleantext\n",
    "\n",
    "# Reference :\n",
    "# https://stackoverflow.com/questions/9662346/python-code-to-remove-html-tags-from-a-string\n",
    "\n",
    "'''\n",
    "Replace the contraction words into two parts (by given contraction list)\n",
    "'''\n",
    "def replace_contraction(corpus, cont_list):\n",
    "    for i in range(0, cont_list.shape[0]):\n",
    "        corpus = corpus.lower().replace(cont_list[i,0], cont_list[i,1])\n",
    "    return corpus\n",
    "\n",
    "'''\n",
    "Singularize the words by its POS-tag\n",
    "'''\n",
    "def word_singularize(corpus):\n",
    "    from textblob import TextBlob\n",
    "    \n",
    "    text = TextBlob(corpus)\n",
    "    for tag in text.tags:\n",
    "        if tag[1] == 'NNS' and tag[0] != 'yes':\n",
    "            corpus = corpus.replace(tag[0], tag[0].singularize())\n",
    "    return corpus\n",
    "\n",
    "'''\n",
    "Update clean corpus\n",
    "'''\n",
    "def update_corpus_contraction(X_corpus):\n",
    "    cont_list = load_list(\"contraction_list.txt\", ',')\n",
    "    print(cont_list.shape)\n",
    "    print('corpus update start')\n",
    "    for i in range(0,len(X_corpus)):\n",
    "        X_corpus[i] = cleanhtml(X_corpus[i])\n",
    "        X_corpus[i] = replace_contraction(X_corpus[i], cont_list)\n",
    "        X_corpus[i] = word_singularize(X_corpus[i])\n",
    "        X_corpus[i] = X_corpus[i].replace('&', 'and')\n",
    "    print('corpus update end')\n",
    "    print()\n",
    "    return X_corpus\n",
    "\n",
    "'''\n",
    "Count the negative and positive frequency\n",
    "'''\n",
    "def negative_positive_counts(X, y, word_index):\n",
    "    neg_count = np.sum(X[y==0, word_index])\n",
    "    pos_count = np.sum(X[y==1, word_index])    \n",
    "    return neg_count, pos_count\n",
    "\n",
    "'''\n",
    "Count the ratio : log((#pos+1)/(#neg+1)) \n",
    "'''\n",
    "def log_ratio_positive_negative(X, y, word_index):\n",
    "    neg_count, pos_count = negative_positive_counts(X,y, word_index)\n",
    "    log_ratio = np.log(pos_count+1)-np.log(neg_count+1)\n",
    "    return log_ratio, neg_count, pos_count\n",
    "\n",
    "'''\n",
    "Sort top words w.r.t log ratio and write into file\n",
    "'''\n",
    "def sort_top_words_with_count(X, y, words,filename, top_k=10):\n",
    "    log_ratio = []\n",
    "    neg_count = []\n",
    "    pos_count = []\n",
    "    \n",
    "    for i in range(0,len(words)):\n",
    "        log_ratio_, neg_count_, pos_count_ = log_ratio_positive_negative(X, y, i)\n",
    "        log_ratio.append(log_ratio_)\n",
    "        neg_count.append(neg_count_)\n",
    "        pos_count.append(pos_count_)\n",
    "    \n",
    "    sorted_indices_descending_abs = np.argsort(np.absolute(log_ratio))[::-1]\n",
    "    \n",
    "    filename = filename + '.txt'\n",
    "    with open(filename, mode='w', encoding='utf8') as w:\n",
    "        for i in sorted_indices_descending_abs[: top_k]:\n",
    "            w.write(\"%s\\t%0.2f\\t%d\\t%d\" %(str(words[i]), log_ratio[i], neg_count[i], pos_count[i]))\n",
    "            w.write('\\n')\n",
    "        w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the raw corpus from IMDB\n",
    "# return the list of sentences. \n",
    "\n",
    "def get_sentences(corpus):\n",
    "    from textblob import TextBlob\n",
    "    text = TextBlob(corpus)\n",
    "    i = 0\n",
    "    sent = []\n",
    "    for sentence in text.raw_sentences:\n",
    "        sent.append(sentence)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the imdb data\n",
      "Train Data loaded.\n",
      "Test Data loaded.\n"
     ]
    }
   ],
   "source": [
    "# Loading the IMDB data\n",
    "\n",
    "X_train_corpus, y_train, X_test_corpus, y_test = load_imdb(r\"C:\\Users\\Anneke\\Documents\\Dataset\\aclImdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 2)\n",
      "corpus update start\n",
      "corpus update end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "*** WARNING ***\n",
    "This part takes a lot of time to execute. If you wish to access the pickle file which I already load and clean the data,\n",
    "Please take a look on the function in the block below this block.\n",
    "'''\n",
    "\n",
    "# preprocessing the corpus\n",
    "# 1. clean HTML tags\n",
    "# 2. Replace contraction we'll -> we will\n",
    "# 3. singularize word. movies -> movie\n",
    "# 4. Replace & -> 'and'\n",
    "\n",
    "# X_train_corpus_update = update_corpus_contraction(X_train_corpus)\n",
    "# X_test_corpus_update = update_corpus_contraction(X_test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle(path):\n",
    "    import pickle\n",
    "    \n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X\n",
    "\n",
    "X_train_original = open_pickle('./data/imdb_original_preprocessed_xtrain.pickle')\n",
    "X_test_original = open_pickle('./data/imdb_original_preprocessed_xtest.pickle')\n",
    "y_train_original = open_pickle('./data/imdb_original_preprocessed_ytrain.pickle')\n",
    "y_test_original = open_pickle('./data/imdb_original_preprocessed_ytest.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 silent night, deadly night 5 is the very last of the series, and like part 4, it is unrelated to the first three except by title and the fact that it is a christmas-themed horror flick.except to the oblivious, there is some obvious thing going on here...mickey rooney plays a toymaker named joe petto and his creepy son's name is pino.\n",
      "1 ring a bell, anyone?\n",
      "2 now, a little boy named derek heard a knock at the door one evening, and opened it to find a present on the doorstep for him.\n",
      "3 even though it said \"do not open till christmas\", he begins to open it anyway but is stopped by his dad, who scolds him and sends him to bed, and opens the gift himself.\n",
      "4 inside is a little red ball that sprouts santa arm and a head, and proceed to kill dad.\n",
      "5 oop, maybe he should have left well-enough alone.\n",
      "6 of course derek is then traumatized by the incident since he watched it from the stair, but he does not grow up to be some killer santa, he just stops talking.there is a mysterious stranger lurking around, who seems very interested in the toy that joe petto makes.\n",
      "7 we even see him buying a bunch when derek's mom takes him to the store to find a gift for him to ing him out of his trauma.\n",
      "8 and what exactly is this guy doing?\n",
      "9 well, we are not sure but he does seem to be taking these toy apart to see what makes them tick.\n",
      "10 he does keep his landlord from evicting him by promising him to pay him in cash the next day and present him with a \"larry the larvae\" toy for his kid, but of course \"larry\" is not a good toy and gets out of the box in the car and of course, well, thing are not pretty.anyway, eventually what is going on with joe petto and pino is of course revealed, and as with the old story, pino is not a \"real boy\".\n",
      "11 pino is probably even more agitated and naughty because he suffers from \"kenitalium\" (a smooth plastic crotch) so that could account for his evil way.\n",
      "12 and the identity of the lurking stranger is revealed too, and there is even kind of a happy ending of sort.\n",
      "13 whee.a step up from part 4, but not much of one.\n",
      "14 again, brian yuzna is involved, and screaming mad george, so some decent special effect, but not enough to make this great.\n",
      "15 a few leftover from part 4 are hanging around too, like clint howard and neith hunter, but that does not really make any difference.\n",
      "16 anyway, i now have seeing the whole series out of my system.\n",
      "17 now if i could get some of it out of my ain.\n",
      "18 4 out of 5.\n"
     ]
    }
   ],
   "source": [
    "# Extract sentence\n",
    "\n",
    "sentences = get_sentences(X_train_original[0])\n",
    "\n",
    "for i,sent in enumerate(sentences):\n",
    "    print(i, sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
